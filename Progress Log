# Current Projects Journal
1. Gentrification Analysis using Neural Networks/Data Science.
Last worked on: 11/3/2018. Total time: 5 hours

10/19/2018 - I spent an hour setting up this document before beginning some background research into the causes and effects of 
gentrification. Also sent out messages to a few sources asking for any considerations I should make in order to remain 
socially conscious of any broad pictures I might otherwise fail to consider. Seems like an interesting topic with a ton of 
possible avenues for exploration.

10/22/2018 - Another hour on gentrification, this time finishing the first overview article and beginning another on one 
approach which used Yelp reviews to quantify gentrification. There's certainly research related to what I'd like to study 
here, which is simultaneously promising and daunting because I'll need to differentiate my methods explicitly.

10/23/2018 - Spent the hour today studying what APIs are by following through about half of an hour-long video on Web APIs. 
I've so far learned the basic processes for using and meaning of web APIs as well as a few examples of how they can be used.

10/24/2018 - In my hour today, I finished the API video and read multiple articles on uses of big data on analyzing city 
dynamics. I've compiled a number of sources on both big data uses relating to cities and some on useful APIs. These two 
avenues will round out my knowledge on what's been done in this area of study and similarly give me some ideas for the tools 
already out there regarding API access to datasets/insights. I plan to read through what I've gathered before cutting myself 
off, considering my options, and beginning to develop my own ideas for the project. That's the path forward.

11/3/2018 - I went through the sources on useful APIs and decided pretty quickly that I'll need to and want to find the APIs 
relevant to this project on my own; broad API lists aren't very specialized. After this realization, I spent the rest of the 
hour researching previous methods for clustering neighborhoods. Data Iku has a great example on this, and I'll read through 
their methods before looking to additional ways I could cluster neighborhoods. My thought process is that the clustering will 
determine to what degree we can segment and therefore evaluate our final prediction model. We thus need to ensure that the 
clustering is as accurate and specific as possible.

2. LSTMjazz - Working to generate jazz improv using ML somehow.
Last worked on: 11/17/2018. Total time: 3.5 hours

11/3/2018 - Spent an hour polishing up the very beginning of the legacy file, learning Github basics, and beginning to look 
into alternative/additional datasets. Today was really just to begin the cleanup needed to transition a hackathon project into 
an independent goal-oriented project.

11/10/2018 - Spent an hour and a half working on installing MuseScore and Lilypond into the environment of a Colab notebook. 
It's quite a hassle, clearly, but my goal here is to give the notebook the ability to display PNGs of the music that's going 
on. I feel like this is an important piece to make the data accessible, so I'll keep working on this. I just got to the point 
where the two applications/packages are installed and referenced properly for music21; up next is accessing and displaying the 
PNG files that we're currently getting as a PosixPaths. Feels pretty close to done.

11/17/2018 - Wasted an hour continuing to try to get Music21 working. At almost every turn, the documentation gives no advice 
for resolving errors and there's zero support in every thread I read on the library. I'll definitely plan to abandon Music21 
if I can't find a way to easily parse through what are now flattened chord/note streams. It's a whole thing.

3. Random Forests on the Kaggle Titanic Dataset - Implementing decision trees and manipulating data using Pandas.
Last worked on: 11/25/2018. Total time: 10 hours

11/9/2018 - Revamped previous efforts on the project, reformatting it for presentation at the UDSC. Next step is still to 
implement the actual Decision Tree class, but Gini is working. Maybe also categorize other categories if possible?

11/12/2018 - Spent an hour studying Pandas syntax and useful methods. I'll be presenting this project this Friday at the UDSC 
and I'll need to better understand Pandas prior to presenting about it. Made some tweaks to the notebook to clean things up 
and add useful information/resources. I'll need about two hours more to finish the Kaggle Pandas tutorial I'm going through.

11/15/2018 - I spent a total of three hours finishing off the end of the notebook as it will be presented tomorrow. I've added 
methods to calculate entropy and information gain, engineered a few useful features, and cleaned up the mess that was my 
initial attempt at coding Gini Impurity. I've stopped just short of coding the actual decision tree class. Frankly, I'm unsure 
exactly how such an implementation's supposed to store the decisions and whatnot. I'll figure that out after presenting.

11/16/2018 - 30min: Notebook completed as it will be presented today. Everything including information gain works as expected.

11/25/2018 - 3hr: Over the past few days, since Thanksgiving, I've been reading through an in-depth article on all things 
related to decision trees. It's been a great way to round out my knowledge on the topic so far and I feel like I'm really 
getting these concepts finally in a comprehensive way. I've gone through a bunch and hope to finish soon before coding these 
things out. Titanic's a good start but we should test our code on other datasets as well, once we're there.

4. Blocktr[AI]n - A library for Keras models using some variation on Blockchain. Total time: 0 hours
